## Non-parameter testing
https://www.zhihu.com/column/p/49472487

## MS ExP
[Ron Kohavi KDD 2015 Talk](https://www.youtube.com/watch?v=ZfhQ-fIg4EU&feature=youtu.be&t=2m59s)

- Bing ads
- Bing search

Good resource: [Exp-platform](https://exp-platform.com/2018StrataABtutorial/)

## [Optimizely KDD 2017 Paper Talk](https://www.youtube.com/watch?v=AJX4W3MwKzU)
- Sequential Testing

## [Multi-arm/Contextual bandit](https://multithreaded.stitchfix.com/blog/2018/11/08/bandits/)

## Cases 
#### Uber
- https://eng.uber.com/xp/
- https://eng.uber.com/analyzing-experiment-outcomes

#### Airbnb
Dynamic P, cluster-based, variance reduction
- https://medium.com/airbnb-engineering/experiments-at-airbnb-e2db3abf39e7 
- https://medium.com/airbnb-engineering/experimentation-measurement-for-search-engine-optimization-b64136629760
- https://youtu.be/rxQ6D-QQMWc?t=728

#### Patreon (small company)

https://patreonhq.com/please-please-dont-a-b-test-that-980a9630e4fb (公开了内部的Experiment Template)

https://patreonhq.com/thats-not-a-hypothesis-25666b01d5b4

#### [Inscart](https://tech.instacart.com/it-all-depends-4bb7b22e854b)
- In their logistics system, we cannot split samples either by customer or by shopper since they are all interdependent.

Some ways:
- Simulation: we “replayed” the history of customer and shopper behaviors with the existing algorithm. It's mising lots of other info like feedback loop, capacity and cnanot meausre guardrail metrics directly
- Before and after: it is not clear how much of the effect was caused by exogenous factors such as weather conditions.
- DID: SF vs Oakland: Oakland is far from being a perfect representation of SF. There is an endless list of other factors which might be at play such as traffic conditions, customer promotions, system changes, etc.


They split samples by zone and day
- ttest
- linear regression(equivalent to ttest)
- multivariate: isolate other factors we care about zoen, DoW, week number

By controlling for other variables, multivariate regression dramatically reduces the standard error of the estimate and hence the p-value and false negatives


[How long: run a power analysis to determine the sample size]
(https://docs.google.com/presentation/d/1mxKfEEcVZjup8tCNiYw0g6aeZ8T1G6Sr74mE2Xe7Wtg/edit#slide=id.g4ed02fc4e4_0_78)
Examine variability of the effect estimate via sampling distributions(each distribution is generated by running A/A 500 times)

#### Netflix
https://medium.com/netflix-techblog/its-all-a-bout-testing-the-netflix-experimentation-platform-4e1ca458c15 

## When should we A/B testing:
- Established products: UI, Function
- Fledgling products

## Analyze
- [HTE](http://www.unofficialgoogledatascience.com/2019/04/misadventures-in-experiments-for-growth.html)
- [Percent increase](http://jwegan.com/growth-hacking/wrong-way-to-analyze-experiments/)
- [Udacity Case](https://github.com/shubhamlal11/Udacity-AB-Testing-Final-Project)

## Consideration
- Long term goal: https://research.google/pubs/pub43887/


## Network Effect
- [Linkedin graph clustering method](https://engineering.linkedin.com/blog/2019/06/detecting-interference--an-a-b-test-of-a-b-tests)
  - Cluster the LinkedIn graph into 10,000 clusters. The graph comprises all active LinkedIn members as nodes and their “connections” as edges.  
  - Split these clusters into two parallel experiments: individual vs cluster based
- Doordash: time switchback 
- Inscart: zone and day
